#import "./preprint_format.typ": *

#show: preprint.with(
  presentation: [口頭発表の原稿],
  title: "RPGのラスボス撃破時におけるクライマックス演出の最適化に関する研究",
  author: "川口 達也",
  university: [],
  faculty: [],
  department: [],
  major: [],
  field: [],
  laboratory: [],
  date: ("2025", "7", "5"),
  bibliography-file: "bib/jaist_essay.bib",
)

= タイトル
それでは，RPGのラスボス撃破時におけるクライマックス演出の最適化に関する研究と題しまして，口頭発表の方を始めさせていただきます．

// まるまるカットも検討
// = 専攻を変えた理由
// まず初めに，学部での研究内容と，専攻を変えようと思った理由について簡単に説明します．
// 学部では分子シミュレーションに機械学習を応用する研究に取り組みました．
// しかし，限られた期間では理論を理解するのに精一杯で，機械学習のモデル設計まで深く踏み込むことができなかったことが心残りでした．
// そのため，大学院では最低でも機械学習を使った研究に取り組みたいと考えていました．
// そうして研究室を探す中で，ゲームAIを扱う興味深い研究室を見つけたので，もともとゲームにも関心があったことから，JAISTの情報科学分野を志望いたしました．
// ここまで

= 研究背景

ゲームAIの一般的な使われ方の説明）

本研究では、プレイヤーのゲーム体験における感動を最大化させるという観点から、
プレイヤーの感情を揺さぶる展開の動的制御や、自然な音楽遷移



// このような研究は、ヒューマンコンピュータインタラクション分野において、
// 感情を推定して人に合わせるといった応用が考えられます。






ゲームAIにおける強化学習の応用は広がっていますが、プレイヤーの感動体験の最適化を目的とした研究は、まだ十分に行われていません。

= 研究目的
これを受けまして本研究では，ゲーム体験における展開の動的制御と音楽演出の2つに着目し、強化学習を用いてプレイヤーに最高の感動体験を届けることを目的とします。
本研究では，ラスボス戦の感動体験の要素として，展開の動的制御と音楽演出に着目します。

= 研究手法
続いて、具体的な研究手法についてご説明いたします。
本研究では、「コマンド選択型のRPGにおけるラスボス戦」を題材とします。
この題材を選定した理由は、大きく3つあります。
1つ目は、RPGは没入感を重視するゲームジャンルであり、感動体験との親和性が高いこと。
2つ目は、コマンド選択型のゲームは状態が不連続であり、強化学習の設計が比較的シンプルで、修士課程の研究として扱いやすいこと。
3つ目は、ラスボス戦はゲーム全体のクライマックスであり、プレイヤーの記憶に強く残る重要な場面であることです。

// カット
// 強化学習とは，エージェントが環境の中で行動し，その結果得られる報酬をもとに，「どのように行動すれば最適かを学習する機械学習の一種です．
// たとえば囲碁を例にすると，環境とはゲームのルールと盤面，エージェントとは強くしたい対戦プレイヤーに相当します．
// 対戦プレイヤーAIは，状態と呼ばれる，現在の盤面の碁石の配置を見ながら，行動と呼ばれる，次にどこに石を置くかを選びます．
// そして，対局を通じて得られる勝敗などの報酬をもとに，AIがプレイヤーのように経験を積みながら，より良い行動の選び方を自ら学んでいくのが，強化学習の特徴です．
機械学習の方はpythonで処理を行います．
本研究では，強化学習アルゴリズムとしてDeep Q-Networkを使います．（以下ではDQNと呼びます）
DQNは強化学習にニューラルネットワークの技術を応用した手法です．

= 研究手法｜強化学習

強化学習の概要、報酬関数の説明

= 研究手法｜音楽演出
続いて音楽演出についてです．
ラスボス戦における音楽は，プレイヤーの感情に直接働きかける重要な要素です．
ゲーム音楽が映画などの音楽と違う点として，ループすることが挙げられます．
近年では，ゲームの状況に応じて音楽を変化させるインタラクティブミュージックという技術が注目されています．
この技術自体は昔から研究されており，近年ではFF15のボス戦において，メインパートとエンドパートの間にプレエンドパートを設け，そのパートではループ間隔を短くすることで，いつでもエンドパートに遷移できる工夫がされています．
こうした工夫によって，ボス戦のBGMがそのまま自然に勝利BGMへと移る演出が可能になりますが、同じような展開の音楽になってしまう問題などがあります。
このようにインタラクティブミュージックでは，ゲームの状況に応じて音楽を変化させる取り組みが進められてきました．しかしその一方で，音楽に合わせてゲームの状況を変化させるという逆のアプローチはまだあまり行われていません．

= 研究手法｜BGMと報酬関数
背景で述べた通り、音楽を変化させることは行わず、あらかじめ決まった音楽に合わせて、ラスボスの行動を制御します。
報酬関数はこの音楽に基づいて設計します。
BGMはループの一番最後に最も盛り上がると仮定します．
灰色の縦の点線がループが終了するタイミングです．
報酬関数はこのBGMを元にこのように設定します．
ループの終盤の近くでラスボスを倒すほど，点数が高くなりますが，少しでも超えると点数を大幅に下げます．
これは，多少早い場合は自然に勝利BGMに繋げられますが，少しでも遅い場合は繋げられないことが理由です．
// また，状態にはBGMのループ時間を1となるように時間を正規化し，現在の時刻を0～1の数値として状態に含めることで，今がループのどのあたりかエージェントが把握できるようにします．（ここジェスチャー）


= 研究手法｜没入感のための演出
続いて，さらにプレイヤーを熱くさせる要素として，攻撃の命中や回避，クリティカル攻撃などの運要素を取り入れ，これらを意図的に確率操作することをします．
また，ゲーム中盤の報酬として，これらに示されるような，プレイヤーを熱くさせる展開があった場合には，報酬関数に加点を行い，ゲームの序盤から中盤はこれに基づいて学習を行います．
これらは一例ですが，後に説明する方法によって加点方法を追加したりブラッシュアップを行います．

= 研究手法｜評価方法
続いて，結果の評価方法について説明します．
// 学習後のエージェントについて，討伐時間のヒストグラムを作成し，ループ終了タイミングとの一致度を定量的に評価します．
実際に人にプレイしてもらい，GEQと呼ばれる，ゲームの評価によく用いられる分析手法に基づいてアンケートを実施します．
質問項目では，プレイ中に抱いた最もふさわしい感情についていくつか選択してもらい，それをこれらの7つの感情に分類し，合わせてそれを感じた場面を答えてもらうことで，特定のイベントがどの感情に効果的だったかフィードバックすることで，先ほどの熱くなる展開，イベントの更新を行います．

// 残り時間次第でカット
= 課題，今後の展望
最後に課題及び今後の展望について考察します．
本研究は，ゲームAIが演出と連携し，プレイヤー体験を最適化する新しい可能性を提示する研究です．
課題としては，なかなかちょうどいいタイミングでプレイヤーがコマンドを選択してくれない場合，戦闘が終結せずグダってしまうことや，〜などが考えられます．
今後の展望としては，複数キャラクターによるパーティバトルや，アクションゲームなどのリアルタイム性の高いジャンルへの応用なども期待できます．
以上で発表を終わります．
ご清聴ありがとうございました．
