#import "./preprint_format.typ": *

#show: preprint.with(
  presentation: [口頭発表の原稿],
  title: "RPGのラスボス撃破時におけるクライマックス演出の最適化に関する研究",
  author: "川口 達也",
  university: [],
  faculty: [],
  department: [],
  major: [],
  field: [],
  laboratory: [],
  date: ("2025", "7", "5"),
  bibliography-file: "bib/jaist_essay.bib",
)

= タイトル
それでは，RPGのラスボス撃破時におけるクライマックス演出の最適化に関する研究と題しまして，口頭発表の方を始めさせていただきます．

// まるまるカット
// = 専攻を変えた理由
// まず初めに，学部での研究内容と，専攻を変えようと思った理由について簡単に説明します．
// 学部では分子シミュレーションに機械学習を応用する研究に取り組みました．
// しかし，限られた期間では理論を理解するのに精一杯で，機械学習のモデル設計まで深く踏み込むことができなかったことが心残りでした．
// そのため，大学院では最低でも機械学習を使った研究に取り組みたいと考えていました．
// そうして研究室を探す中で，ゲームAIを扱う興味深い研究室を見つけたので，もともとゲームにも関心があったことから，JAISTの情報科学分野を志望いたしました．
// ここまで

= 研究背景
近年，人工知能は様々な分野で研究されており，ゲームにおいても，チェスや囲碁などで人間のトッププレイヤーを凌駕するほどの強さを持つAIが登場しています．
このような背景から，ゲームAIといえば人間に勝つために作られたものを連想しがちですが，必ずしも強さを追求するわけではありません．
近年では，プレイヤーを楽しませてくれるように手加減をするAIの研究が注目されています．
例えば，囲碁において，プレイヤーにとって弱すぎず強すぎない手を打ってくれるAIの研究例などがあります．
このように，面白さを追求するためのAIの研究は盛んにおこなわれています．
一方で，感動的な体験もまたゲームの面白さを構成する重要な要素です．
プレイヤーの記憶に残るような緊張感や達成感の演出は，ゲーム全体の評価や満足度に大きく影響します．
しかしながら，こうした感動体験そのものをAIによって最適化することを目指した研究は，まだ十分に行われているとは言えません．

= 研究目的
そこで本研究では，プレイヤーに感動を届けるゲーム体験の実現を目的として，強化学習を用いたゲーム演出の最適化に取り組みます．
本研究では，音楽演出と感情を揺さぶる展開の動的制御の2つに着目します．
ゲームにおける音楽は，場面の緊張感や高揚感を演出し，バトルの展開と連携することで，プレイヤーの感情に影響を与える重要な要素です．
また，音楽演出に加えて，プレイヤーを熱くさせる展開を意図的に起こすことを行います．
// また，音楽演出に加えて，プレイヤーの感情曲線を意図的に設計し，それに沿った演出を行うことで，没入感や達成感の向上を目指します．

= 研究手法
続いて，具体的な研究手法についてご説明いたします．
本研究では，「コマンド選択型のRPGにおけるラスボス戦」を題材とします．
この題材を選定した理由は，大きく3つあります．
1つ目は，RPGは没入感を重視するゲームジャンルであり，感動体験との親和性が高いこと．
2つ目は，コマンド選択型のゲームは状態が不連続であり，強化学習の設計が比較的シンプルで，修士課程の研究として扱いと考えられること．
3つ目は，ラスボスがゲーム全体のクライマックスであり，プレイヤーの記憶に強く残る重要な場面であることです．

= 研究手法｜ゲーム制作
// 機械学習の方はpythonで処理を行います．
// 本研究では，強化学習アルゴリズムとしてDeep Q-Networkを使います．（以下ではDQNと呼びます）
// DQNは強化学習にニューラルネットワークの技術を応用した手法です．

= 研究手法｜強化学習
続いて，強化学習について簡単に説明します．
強化学習とは，エージェントが環境の中で行動し，その結果得られる報酬をもとに，「どのように行動すれば最適かを学習する機械学習の一種です．
たとえば囲碁を例にすると，環境とはゲームのルールと盤面，エージェントとは強くしたい対戦プレイヤーに相当します．
対戦プレイヤーAIは，状態と呼ばれる，現在の盤面の碁石の配置を見ながら，行動と呼ばれる，次にどこに石を置くかを選びます．
そして，対局を通じて得られる勝敗などの報酬をもとに，AIがプレイヤーのように経験を積みながら，より良い行動の選び方を自ら学んでいくのが，強化学習の特徴です．

（状態，行動が一目でわかるように，スライドを作り直すべき）

= 研究手法｜音楽演出
続いて音楽演出についてです．
ゲーム音楽が映画などのものと違う点として，ループすることが挙げられます．
近年では，ゲームの状況に応じて音楽を変化させるインタラクティブミュージックという技術が注目されています．
この技術自体は昔から研究されており，近年ではFF15のボス戦において，メインパートとエンドパートの間にプレエンドパートを設け，そのパートではループ間隔を短くすることで，いつでもエンドパートに遷移できる工夫がされています．
こうした工夫によって，ボス戦のBGMがそのまま自然に勝利BGMへと移る演出が可能になりますが，同じような展開の音楽になってしまう問題などがあります．
このようにインタラクティブミュージックでは，ゲームの状況に応じて音楽を変化させる取り組みが進められてきました．しかしその一方で，音楽に合わせてゲームの状況を変化させるという逆のアプローチはまだあまり行われていません．

= 研究手法｜BGMと報酬関数
そのため，本研究では，音楽を変化させることは行わず，あらかじめ決まった音楽に合わせて，ラスボスの行動を制御します．
BGMはループの一番最後に最も盛り上がると仮定します．
灰色の縦の点線がループが終了するタイミングです．
報酬の関数をこのように設定します．
ループの終盤の近くでラスボスを倒すほど，点数が高くなりますが，少しでも超えると点数を大幅に下げます．
これは，多少早い場合は自然に勝利BGMに繋げられますが，少しでも遅い場合は繋げられないことが理由です．
// また，状態にはBGMのループ時間を1となるように時間を正規化し，現在の時刻を0～1の数値として状態に含めることで，今がループのどのあたりかエージェントが把握できるようにします．（ここジェスチャー）

= 研究手法｜展開の動的制御
続いて，プレイヤーをさらに盛り上げる展開の制御方法をいくつか説明します．
まず，攻撃の命中や回避，会心の一撃などの運要素を取り入れ，これらを意図的に確率操作することをします．
続いて，リアルタイムで勝敗予測を行います．これによって，プレイヤーの極端に下手な行動に対しては，容赦なく攻撃することで，無粋な手加減を防ぎます．
また，顔の表情や脈拍などといった生体情報を用いずに，コマンド選択時間や選択傾向，待機中のボタン入力などで感情を推定することを行います．

次に，ゲーム序盤から中盤にかけて，プレイヤーが熱くなる展開が発生した場合には，それに応じて報酬関数に加点を行います．
初めは，「会心の一撃でラスボスを倒す」などの印象的な展開をあらかじめ設定し，それが起これば加点する仕組みとします．
続いて，実際のプレイヤーにゲームを体験してもらい，GEQと呼ばれる，ゲームの評価によく用いられる分析手法に基づいたアンケートを実施します．
プレイヤーには，プレイ中に感じた感情と，それが生じた場面を答えてもらい，その結果から，どのイベントがどのような感情を引き起こしたのかを分析します．
こうしたフィードバックをもとに，熱くなる展開やイベントの内容を更新していきます．

= 計画

