#import "./preprint_format.typ": *

#show: preprint.with(
  presentation: [口頭発表の原稿],
  title: "RPGのラスボス撃破時におけるクライマックス演出の最適化に関する研究",
  author: "川口 達也",
  university: [],
  faculty: [],
  department: [],
  major: [],
  field: [],
  laboratory: [],
  date: ("2025", "7", "5"),
  bibliography-file: "bib/jaist_essay.bib",
)

= タイトル
それでは，RPGのラスボス撃破時におけるクライマックス演出の最適化に関する研究と題しまして，口頭発表の方を始めさせていただきます．

// まるまるカット
// = 専攻を変えた理由
// まず初めに，学部での研究内容と，専攻を変えようと思った理由について簡単に説明します．
// 学部では分子シミュレーションに機械学習を応用する研究に取り組みました．
// しかし，限られた期間では理論を理解するのに精一杯で，機械学習のモデル設計まで深く踏み込むことができなかったことが心残りでした．
// そのため，大学院では最低でも機械学習を使った研究に取り組みたいと考えていました．
// そうして研究室を探す中で，ゲームAIを扱う興味深い研究室を見つけたので，もともとゲームにも関心があったことから，JAISTの情報科学分野を志望いたしました．
// ここまで

= 研究背景
近年，人工知能は様々な分野で研究されており，ゲームにおいても，チェスや囲碁などで人間のトッププレイヤーを凌駕するほどの強さを持つAIが登場しています．
このような背景から，ゲームAIといえば人間に勝つために作られたものを連想しがちですが，必ずしも強さを追求するわけではありません．
近年では，プレイヤーを楽しませてくれるように手加減をするAIの研究が注目されています．
例えば，囲碁において，プレイヤーにとって弱すぎず強すぎない手を打ってくれるAIの研究例などがあります．
このように，面白さを追求するためのAIの研究は盛んにおこなわれています．
一方で，感動的な体験もまたゲームの面白さを構成する重要な要素です．
プレイヤーの記憶に残るような緊張感や達成感の演出は，ゲーム全体の評価や満足度に大きく影響します．
しかしながら，こうした感動体験そのものをAIによって最適化することを目指した研究は，まだ十分に行われているとは言えません．

= 研究目的
そこで本研究では，プレイヤーに感動を届けるゲーム体験の実現を目的として，強化学習を用いたゲーム演出の最適化に取り組みます．
本研究では，音楽演出と感情を揺さぶる展開の動的制御の2つに着目します．
ゲームにおける音楽は，場面の緊張感や高揚感を高める重要な要素であり，バトルの展開と連携することで，プレイヤーの感情に大きな影響を与えます．
また，音楽演出に加えて，プレイヤーの感情曲線を意図的に設計することで，没入感や達成感を高めることを目指します．

= 研究手法
続いて，具体的な研究手法についてご説明いたします．
本研究では，「コマンド選択型のRPGにおけるラスボス戦」を題材とします．
この題材を選定した理由は，大きく3つあります．
1つ目は，RPGは没入感を重視するゲームジャンルであり，感動体験との親和性が高いこと．
2つ目は，コマンド選択型のゲームは状態が不連続であり，強化学習の設計が比較的シンプルで，修士課程の研究として扱いやすそうであること．
3つ目は，ラスボスがゲーム全体のクライマックスであり，プレイヤーの記憶に強く残る重要な場面であることです．

// 機械学習の方はpythonで処理を行います．
// 本研究では，強化学習アルゴリズムとしてDeep Q-Networkを使います．（以下ではDQNと呼びます）
// DQNは強化学習にニューラルネットワークの技術を応用した手法です．

= 研究手法｜強化学習
続いて、強化学習について簡単に説明します。
強化学習とは，エージェントが環境の中で行動し，その結果得られる報酬をもとに，「どのように行動すれば最適かを学習する機械学習の一種です．
たとえば囲碁を例にすると，環境とはゲームのルールと盤面，エージェントとは強くしたい対戦プレイヤーに相当します．
対戦プレイヤーAIは，状態と呼ばれる，現在の盤面の碁石の配置を見ながら，行動と呼ばれる，次にどこに石を置くかを選びます．
そして，対局を通じて得られる勝敗などの報酬をもとに，AIがプレイヤーのように経験を積みながら，より良い行動の選び方を自ら学んでいくのが，強化学習の特徴です．

（状態，行動が一目でわかるように，スライドを作り直すべき）

= 研究手法｜音楽演出
続いて音楽演出についてです．
// ラスボス戦における音楽は，プレイヤーの感情に直接働きかける重要な要素です．
ゲーム音楽が映画などのものと違う点として，ループすることが挙げられます．
近年では，ゲームの状況に応じて音楽を変化させるインタラクティブミュージックという技術が注目されています．
この技術自体は昔から研究されており，近年ではFF15のボス戦において，メインパートとエンドパートの間にプレエンドパートを設け，そのパートではループ間隔を短くすることで，いつでもエンドパートに遷移できる工夫がされています．
こうした工夫によって，ボス戦のBGMがそのまま自然に勝利BGMへと移る演出が可能になりますが，同じような展開の音楽になってしまう問題などがあります．
このようにインタラクティブミュージックでは，ゲームの状況に応じて音楽を変化させる取り組みが進められてきました．しかしその一方で，音楽に合わせてゲームの状況を変化させるという逆のアプローチはまだあまり行われていません．

= 研究手法｜BGMと報酬関数
そのため，本研究では，音楽を変化させることは行わず，あらかじめ決まった音楽に合わせて，ラスボスの行動を制御します．
BGMはループの一番最後に最も盛り上がると仮定します．
灰色の縦の点線がループが終了するタイミングです．
報酬関数はこのBGMを元にこのように設定します．
ループの終盤の近くでラスボスを倒すほど，点数が高くなりますが，少しでも超えると点数を大幅に下げます．
これは，多少早い場合は自然に勝利BGMに繋げられますが，少しでも遅い場合は繋げられないことが理由です．
// また，状態にはBGMのループ時間を1となるように時間を正規化し，現在の時刻を0～1の数値として状態に含めることで，今がループのどのあたりかエージェントが把握できるようにします．（ここジェスチャー）


= 研究手法｜展開の動的制御
続いて，さらにプレイヤーを熱くさせる要素として，攻撃の命中や回避，クリティカル攻撃などの運要素を取り入れ，これらを意図的に確率操作することをします．
また，ゲーム中盤の報酬として，これらに示されるような，プレイヤーを熱くさせる展開があった場合には，報酬関数に加点を行い，ゲームの序盤から中盤はこれに基づいて学習を行います．
これらは一例ですが，後に説明する方法によって加点方法を追加したりブラッシュアップを行います．

= 研究手法｜評価方法
続いて，結果の評価方法について説明します．
// 学習後のエージェントについて，討伐時間のヒストグラムを作成し，ループ終了タイミングとの一致度を定量的に評価します．
実際に人にプレイしてもらい，GEQと呼ばれる，ゲームの評価によく用いられる分析手法に基づいてアンケートを実施します．
質問項目では，プレイ中に抱いた最もふさわしい感情についていくつか選択してもらい，それをこれらの7つの感情に分類し，合わせてそれを感じた場面を答えてもらうことで，特定のイベントがどの感情に効果的だったかフィードバックすることで，先ほどの熱くなる展開，イベントの更新を行います．

= 計画

