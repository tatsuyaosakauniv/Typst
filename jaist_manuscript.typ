#import "./preprint_format.typ": *

#show: preprint.with(
  presentation: [口頭発表の原稿],
  title: "RPGのボス撃破時におけるクライマックス演出の最適化に関する研究",
  author: "川口 達也",
  university: [],
  faculty: [],
  department: [],
  major: [],
  field: [],
  laboratory: [],
  date: ("2025", "7", "5"),
  bibliography-file: "bib/jaist_essay.bib",
)

= タイトル
それでは，RPGのボス撃破時におけるクライマックス演出の最適化に関する研究と題しまして，口頭発表の方を始めさせていただきます．

= 研究背景
// 近年，人工知能は様々な分野で研究されており，ゲームにおいても，チェスや囲碁などで人間のトッププレイヤーを凌駕するほどの強さを持つAIが登場しています．
// このような背景から，
まずは背景についてご説明いたします．
ゲームAIと聞かれると、人間に勝つために作られたものを連想しがちですが，必ずしも強さだけを追求するわけではありません．
近年では，プレイヤーを楽しませてくれるように手加減をするAIの研究が注目されています．
例えば，囲碁において，プレイヤーにとって強すぎず弱すぎない手を打ってくれるAIの研究例などがあります．
このように，面白さを追求するためのAIの研究は今もなお盛んにおこなわれています．

= 研究背景
一方で，感動的な体験もまたゲームの面白さを構成する重要な要素です．
プレイヤーの記憶に残るような緊張感や達成感の演出は，ゲーム全体の評価や満足度に大きく影響します．
プレイヤーの感情を顔の表情や脈拍といった生体情報で判断する研究例はありますが，
こうした感動体験そのものをAIによって最適化することを目指した研究は，まだ十分に行われているとは言えません．

= 研究目的
そこで本研究では，強化学習を用いてゲーム演出を心理的に最適化することで，プレイヤーに感動的な体験を提供することを目的とします。
本研究では，音楽に同期するためのAI制御と感情的な展開の制御の2つに着目します．
のちに詳しく説明しますが、音楽同期のAI制御では、プレイヤーに違和感なく音楽が展開されるよう、BGMに合わせてAIの行動を制御します。
また、感情的展開の制御では、感情曲線に基づき、プレイヤーの心に残る印象的な展開を意図的に演出することを目指します。

= 研究手法｜コマンドRPGのボス戦
続いて，具体的な研究手法についてご説明いたします．
本研究では，「コマンド選択型のRPGにおけるボス戦」を題材とします．
この題材を選定した理由は，大きく3つあります．
1つ目は，RPGが没入感を重視するゲームジャンルであり，感動体験との親和性が高いから．
2つ目は，コマンド選択型のゲームは状態が不連続であり，強化学習の設計が比較的シンプルで扱いやすいと考えられるから．
3つ目は，ボス戦がゲーム全体を通して重要な局面であり，プレイヤーの記憶に強く残るからです．

= 研究手法｜ゲーム制作
// 機械学習の方はpythonで処理を行います．
// 本研究では，強化学習アルゴリズムとしてDeep Q-Networkを使います．（以下ではDQNと呼びます）
// DQNは強化学習にニューラルネットワークの技術を応用した手法です．



= 研究手法｜強化学習
続いて，強化学習について簡単に説明します．
強化学習というのは、ゲームAIによく用いられる機械学習の一種です。
たとえば囲碁を例にすると、AIは盤面とルールを把握しながら、次にどこに石を置くかを考えます。
置いた結果が勝敗につながったかに応じて、報酬と呼ばれるボーナスをもらえます。
この報酬をできるだけ多く得られるように、AIは試行錯誤を繰り返しながら、行動の選び方を学んでいきます。

（状態，行動が一目でわかるように，スライドを作り直すべき）

= 研究背景｜音楽演出
続いて音楽演出についてご説明いたします。
ゲーム音楽は映画音楽などと異なり、ループする点が特徴です。
プレイ時間がプレイヤーに委ねられているため、音楽が途中で途切れると違和感を生じさせてしまいます。
そこで1990年頃からは、ゲームの状況に応じて音楽を変化させる「インタラクティブミュージック」という技術が注目され、音楽を自然につなげる工夫が進められてきました。
例えば2017年に発表されたff15では、ボス戦のBGMにおいて，メインパートとエンドパートの間にプレエンドパートを設け，このパートではループ間隔を短くすることで，いつでも自然にエンドパートへ遷移できるような構成が取られています。
こうした工夫によって，ボス戦のBGMがそのまま自然に勝利BGMへと移る演出が可能になります．
このようにインタラクティブミュージックでは，ゲームの状況に応じて音楽を変化させる取り組みが進められてきましたが、音楽に合わせてゲームの状況を変化させるという逆のアプローチはまだあまり行われていません．

= 研究手法｜BGMと報酬関数
そのため，本研究では，曲のテンポや長さを変化させることは行わず，あらかじめ決められたBGMに合わせて，ゲーム側を制御します．
本研究では、報酬の関数をこのように設定します．
BGMはループの最後に最も盛り上がる部分があると仮定し、その盛り上がりに合わせてボスが倒されるように誘導します。
灰色の縦の点線はループが終了するタイミングを示しています。
ループの終盤付近でボスを倒すほど報酬が高くなります．
こうすることで，ループ終了の手前でボスが倒されて，違和感なく勝利BGMに遷移できると考えています．
// また，状態にはBGMのループ時間を1となるように時間を正規化し，現在の時刻を0～1の数値として状態に含めることで，今がループのどのあたりかエージェントが把握できるようにします．（ここジェスチャー）

= 研究手法｜感情的展開の制御
続いて，あらかじめ設定した感情曲線に基づいて，プレイヤーの感情通りのイベントを起こすことを目指します．

初めは，「会心の一撃でボスを倒す」「HPギリギリで耐える」などの印象的な展開をあらかじめ設定します．
印象的かどうかの評価方法としては，実際のプレイヤーにゲームを体験してもらい，GEQと呼ばれる，ゲームの評価によく用いられる分析手法に基づいたアンケートを実施します．
プレイヤーには，プレイ中に感じた感情と，それが生じた場面を答えてもらい，その結果から，どのイベントがどのような感情を引き起こしたのかを分析します．

また，顔の表情や脈拍などといった生体情報を用いずに，選択したコマンドの内容や傾向，コマンド選択時間，待機中のボタン入力などで感情を推定することを行います．

こうしたフィードバックをもとに，心に残る展開やイベントの内容を更新していきます．

プレイヤーの心に残る展開を，想定していた感情曲線通りに起こすことができた場合には，それに応じて報酬関数に加点を行います．


そのほかの点としては，攻撃の命中や回避，確率的に発生する高威力な攻撃、いわゆる会心の一撃などの運要素を意図的に確率操作することなども考えています．

= 計画

// 予備スライドで説明するかも
// 続いて，リアルタイムで勝敗予測を行います．これによって，プレイヤーの極端に下手な行動に対しては，容赦なく攻撃することで，無粋な手加減を防ぎます．


// まるまるカット
// = 専攻を変えた理由
// まず初めに，学部での研究内容と，専攻を変えようと思った理由について簡単に説明します．
// 学部では分子シミュレーションに機械学習を応用する研究に取り組みました．
// しかし，限られた期間では理論を理解するのに精一杯で，機械学習のモデル設計まで深く踏み込むことができなかったことが心残りでした．
// そのため，大学院では最低でも機械学習を使った研究に取り組みたいと考えていました．
// そうして研究室を探す中で，ゲームAIを扱う興味深い研究室を見つけたので，もともとゲームにも関心があったことから，JAISTの情報科学分野を志望いたしました．
// ここまで