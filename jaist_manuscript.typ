#import "./preprint_format.typ": *

#show: preprint.with(
  presentation: [口頭発表の原稿],
  title: "RPGのボス撃破時におけるクライマックス演出の最適化に関する研究",
  author: "川口 達也",
  university: [],
  faculty: [],
  department: [],
  major: [],
  field: [],
  laboratory: [],
  date: ("2025", "7", "5"),
  bibliography-file: "bib/jaist_essay.bib",
)

== タイトル
それでは，RPGのボス撃破時におけるクライマックス演出の最適化に関する研究と題しまして，口頭発表の方を始めさせていただきます．

== 目次
まずは研究背景についてご説明いたします．

= 研究背景
まずゲームAIと聞かれると，チェスや囲碁などにおいて人間に勝つために作られるものを連想しがちですが，必ずしも強さのみを追求するわけではありません．
近年では，プレイヤーを楽しませてくれるように手加減するAIの研究が注目されています．
例えば，プレイヤーにとって強すぎず弱すぎない手を打つ囲碁AIの研究例などが挙げられます．
このように，面白さを追求するためのAI研究は盛んにおこなわれています．

= 研究背景
一方で，感動的な体験もまたゲームの面白さを構成する重要な要素です．
// プレイヤーの記憶に残るような緊張感や達成感の演出は，ゲーム全体の評価や満足度に大きく影響します．
例えば，人の感情を顔の表情や脈拍といった情報で判断する研究例があります．
しかし，感動体験そのものをAIによって最適化する研究は，まだ十分に行われているとは言えません．

= 研究目的
そこで本研究では，強化学習を用いてゲーム演出を心理的に最適化することで，プレイヤーに感動的な体験を提供することを目的とします．
本研究では，感情的な展開の制御と，音楽に同期するためのAI制御の2つに着目します．
詳細については後ほどご説明いたします．

== 目次
続いて，具体的な研究手法についてご説明いたします．

= 研究手法｜ゲームのテーマ
まず，本研究で扱うゲームについてご説明いたします．
本研究では，「コマンド選択型のRPGにおけるボス戦」を題材とします．
この題材を選定した理由は，大きく3つあります．
1つ目は，RPGが没入感を重視するゲームジャンルであり，感動体験との親和性が高いから．
2つ目は，コマンド選択型のゲームは状態が不連続であり，強化学習の設計が比較的シンプルで扱いやすいと考えられるから．
3つ目は，ボス戦がゲーム全体を通して重要な局面であり，プレイヤーの記憶に強く残るからです．

= 研究手法｜ゲーム制作
本研究では，RPGを自作しようと考えています．
機械学習と連携できるRPGシミュレータにいいものがネットになさそうだったことが理由です．
簡単な設定のものだと，1〜2週間程度でできると思っています．
今だと生成AIもあるので，そこは心配ないと考えています．

= 研究手法｜強化学習
続いて，強化学習について，犬のしつけを例に用いて簡単に説明します．
強化学習とは，ゲームAIなどによく用いられる機械学習の一種です．
例えば，犬に「お座り」を覚えさせたいとします．
犬が「立っている状態からお座りをしたとき」にだけ，報酬として餌を与えると，犬はやがて，餌をたくさんもらうために，お座りを学習していくようになります．
本研究の場合は，目的がプレイヤーを感動させることで，AIはボスのことです．
報酬についてはこのあと詳しくご説明いたします．

= 研究手法｜強化学習アルゴリズム
続いて，研究に用いる強化学習アルゴリズムについて簡単に説明します．
// 機械学習の方はpythonで処理を行います．
// 本研究では，強化学習アルゴリズムとしてDeep Q-Networkを使います．（以下ではDQNと呼びます）
// DQNは強化学習にニューラルネットワークの技術を応用した手法です．

== 目次
続いて，感動演出のための，具体的な強化学習手法について説明いたします．

= 研究手法｜感情的展開の制御
まずは，強化学習を用いて，感情的な展開を制御する方法について説明します．
初期段階では，「HPギリギリで耐える」や「会心の一撃でボスを倒す」といった感情を動かすようなイベントを複数設定し，ボス戦中にランダムに発生させます．
次に，被験者にはこのゲームをプレイしてもらいます．
あわせて，そのときに選択したコマンドや傾向，選択にかかった時間，待機中のボタン操作などのプレイログも記録します．
そして，ゲーム終了後に印象的だった場面とそのときの感情についてアンケートに答えてもらいます．
アンケート結果に基づき，好意的に受け取られた場面は報酬に加点し，逆に否定的な印象を与えた場面では減点することで，感情を動かすイベントと，プレイログを結びつけます．
このプロセスを繰り返すことで，プレイログからプレイヤーの感情を推定し，プレイヤーの感情に合った最適なイベントが起きるようになると考えています．

現状では人間がイベントを作成しているので，感情を動かすイベントをAIが自動で生成したり，
指定した感情曲線に合わせてイベントを展開することで，プレイヤーの感情をコントロールできるようになるとさらに面白くなると考えています．

// そのほかの点としては，攻撃の命中や回避，確率的に発生する高威力な攻撃，いわゆる会心の一撃などの運要素を意図的に確率操作することなども考えています．

= 研究手法｜音楽同期のAI制御
つぎに，音楽に同期するためのAI制御の方法についてご説明いたします．
ボス戦の終わり方は，ゲーム体験の印象を大きく作用します．
特に，BGMが戦闘の決着と同時に自然に終わり，勝利BGMへとスムーズにつながることで，プレイヤーの没入感が維持されます．
そこで，本研究では，先ほど説明した感情的な展開の制御に加え，音楽演出の最適化にも注目します．

= 研究手法｜関連研究
ゲーム音楽は映画音楽などと異なり，ループする点が特徴です．
ゲームの進行がプレイヤーに委ねられているため，音楽が途中で途切れると違和感を生じさせてしまいます．
そこで，ゲームの状況に応じて音楽を変化させる「インタラクティブミュージック」という技術が注目され，音楽を自然につなげる工夫が進められてきました．
例えば2017年に発表されたff15では，ボス戦のBGMにおいて，メインパートとエンドパートの間にプレエンドパートを設け，このパートではループ間隔を短くすることで，いつでも自然にエンドパートへ遷移しやすくする工夫がされています．
こうすることで，滑らかに勝利BGMへつながる演出が可能になります．
しかし，同じような構成をもつ曲が増えるという問題も挙げられます．
このように従来のインタラクティブミュージックでは，ゲームの状況に応じて音楽を変化させる取り組みが進められてきましたが，逆に，音楽に合わせてゲームの状況を変化させるアプローチはまだあまり行われていません．

= 研究手法｜BGMと報酬
そのため，本研究では，曲のテンポや長さを変化させることは行わず，あらかじめ決められたBGMに合わせて，ゲーム側を制御します．
本研究では，報酬をこのような関数に基づいて決定します．
灰色の縦の点線はループが終了するタイミングを示していて，ループの終盤付近でボスを倒すほど報酬を高く与えます．
こうすることで，ループ終了の手前でボスが倒されて，違和感なく勝利BGMに遷移できると考えています．
// また，状態にはBGMのループ時間を1となるように時間を正規化し，現在の時刻を0～1の数値として状態に含めることで，今がループのどのあたりかエージェントが把握できるようにします．（ここジェスチャー）

将来的には，〜などの応用も期待できると思っています．

= まとめ
最後にまとめを提示して終わります．
ご清聴ありがとうございました．

= 計画

// 予備スライドで説明するかも
// 続いて，リアルタイムで勝敗予測を行います．これによって，プレイヤーの極端に下手な行動に対しては，容赦なく攻撃することで，無粋な手加減を防ぎます．


// まるまるカット
// = 専攻を変えた理由
// まず初めに，学部での研究内容と，専攻を変えようと思った理由について簡単に説明します．
// 学部では分子シミュレーションに機械学習を応用する研究に取り組みました．
// しかし，限られた期間では理論を理解するのに精一杯で，機械学習のモデル設計まで深く踏み込むことができなかったことが心残りでした．
// そのため，大学院では最低でも機械学習を使った研究に取り組みたいと考えていました．
// そうして研究室を探す中で，ゲームAIを扱う興味深い研究室を見つけたので，もともとゲームにも関心があったことから，JAISTの情報科学分野を志望いたしました．
// ここまで